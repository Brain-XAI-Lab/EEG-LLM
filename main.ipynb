{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-01T01:49:01.527907Z",
     "start_time": "2024-04-01T01:49:01.204906Z"
    }
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Upload a training file"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b1df2294b2a6e58b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Suppose you data is already ready.\n",
    "\n",
    "client = openAI()\n",
    "\n",
    "client.files.create(\n",
    "  file=open(\"mydata.jsonl\", \"rb\"),  # Put you data in mydata.jsonl\n",
    "  purpose=\"fine-tune\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ba58aaddb7547e84"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create a fine-tuned model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be8a973feae53368"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "client.fine_tuning.jobs.create(\n",
    "  training_file=\"file-test1\", \n",
    "  model=\"davinci-002\",\n",
    "  hyperparameters={\n",
    "      \"n_epochs\":10\n",
    "  }\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "149280126354e6ff"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# below is sample code by OpenAI\n",
    "# You don't have to use all the instructions\n",
    "\n",
    "# List 10 fine-tuning jobs\n",
    "client.fine_tuning.jobs.list(limit=10)\n",
    "\n",
    "# Retrieve the state of a fine-tune\n",
    "client.fine_tuning.jobs.retrieve(\"ftjob-test1\")\n",
    "\n",
    "# Cancel a job\n",
    "client.fine_tuning.jobs.cancel(\"ftjob-test1\")\n",
    "\n",
    "# List up to 10 events from a fine-tuning job\n",
    "client.fine_tuning.jobs.list_events(fine_tuning_job_id=\"ftjob-test1\", limit=10)\n",
    "\n",
    "# Delete a fine-tuned model (must be an owner of the org the model was created in)\n",
    "# client.models.delete(\"ft:gpt-3.5-turbo:acemeco:suffix:abc123\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca61b289e65dee39"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Yse a fine-tuned model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "353c87e0e35adc60"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Error code: 404 - {'error': {'message': 'The model `ft:gpt-3.5-turbo:my-org:custom_suffix:id` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNotFoundError\u001B[0m                             Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/10/mbcg1njx7fx5cgtqbk198z0m0000gn/T/ipykernel_5047/3841043847.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      6\u001B[0m   messages=[\n\u001B[1;32m      7\u001B[0m     \u001B[0;34m{\u001B[0m\u001B[0;34m\"role\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;34m\"system\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"content\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;34m\"You are a helpful assistant.\"\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 8\u001B[0;31m     \u001B[0;34m{\u001B[0m\u001B[0;34m\"role\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;34m\"user\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"content\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;34m\"Hello!\"\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      9\u001B[0m   ]\n\u001B[1;32m     10\u001B[0m )\n",
      "\u001B[0;32m~/miniconda3/lib/python3.7/site-packages/openai/_utils/_utils.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    273\u001B[0m                         \u001B[0mmsg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    274\u001B[0m                 \u001B[0;32mraise\u001B[0m \u001B[0mTypeError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmsg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 275\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    276\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    277\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mwrapper\u001B[0m  \u001B[0;31m# type: ignore\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.7/site-packages/openai/resources/chat/completions.py\u001B[0m in \u001B[0;36mcreate\u001B[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001B[0m\n\u001B[1;32m    697\u001B[0m             \u001B[0mcast_to\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mChatCompletion\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    698\u001B[0m             \u001B[0mstream\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstream\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 699\u001B[0;31m             \u001B[0mstream_cls\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mStream\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mChatCompletionChunk\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    700\u001B[0m         )\n\u001B[1;32m    701\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.7/site-packages/openai/_base_client.py\u001B[0m in \u001B[0;36mpost\u001B[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1206\u001B[0m             \u001B[0mmethod\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"post\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0murl\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mjson_data\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mbody\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfiles\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mto_httpx_files\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfiles\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0moptions\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1207\u001B[0m         )\n\u001B[0;32m-> 1208\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mcast\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mResponseT\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrequest\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcast_to\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mopts\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstream\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstream\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstream_cls\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstream_cls\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1209\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1210\u001B[0m     def patch(\n",
      "\u001B[0;32m~/miniconda3/lib/python3.7/site-packages/openai/_base_client.py\u001B[0m in \u001B[0;36mrequest\u001B[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[1;32m    900\u001B[0m             \u001B[0mstream\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstream\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    901\u001B[0m             \u001B[0mstream_cls\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstream_cls\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 902\u001B[0;31m             \u001B[0mremaining_retries\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mremaining_retries\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    903\u001B[0m         )\n\u001B[1;32m    904\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.7/site-packages/openai/_base_client.py\u001B[0m in \u001B[0;36m_request\u001B[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[1;32m    986\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    987\u001B[0m             \u001B[0mlog\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdebug\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Re-raising status error\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 988\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_make_status_error_from_response\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0merr\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mresponse\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    989\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    990\u001B[0m         return self._process_response(\n",
      "\u001B[0;31mNotFoundError\u001B[0m: Error code: 404 - {'error': {'message': 'The model `ft:gpt-3.5-turbo:my-org:custom_suffix:id` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"ft:gpt-3.5-turbo:my-org:custom_suffix:id\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hello!\"}\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T12:32:50.041518Z",
     "start_time": "2024-04-02T12:32:49.350657Z"
    }
   },
   "id": "fe065373543f4a2f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b94ac0abfdcca34f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
